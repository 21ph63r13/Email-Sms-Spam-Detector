# Email-Sms-Spam-Detector

ğŸ”— Live Demo

Check out the deployed app on Render: https://email-sms-spam-detector-sxuq.onrender.com

A machine learning-based web application that classifies messages as Spam or Not Spam using Natural Language Processing (NLP). The model is trained on a labeled dataset of SMS messages and deployed using Streamlit.

ğŸ“‚ Project Structure
Email-SMS-Spam-Detector/
â”‚â”€â”€ app.py                # Streamlit web app
â”‚â”€â”€ sms_spam_detection.ipynb # Jupyter Notebook (model training)
â”‚â”€â”€ vectorizer.pkl        # TF-IDF vectorizer (saved model)
â”‚â”€â”€ model.pkl             # Trained NaÃ¯ve Bayes model
â”‚â”€â”€ requirements.txt      # Dependencies
â”‚â”€â”€ README.md             # Project Documentation


ğŸ“Œ Features

âœ… Text preprocessing using stopword removal & stemming

âœ… TF-IDF Vectorization for text feature extraction

âœ… NaÃ¯ve Bayes Classification for message prediction

âœ… User-friendly Web Interface using Streamlit

âœ… Deployed on Render for easy access

ğŸ“ Dataset

The dataset used for training consists of labeled SMS messages, where:
ham represents non-spam messages.
spam represents unwanted promotional messages.
The dataset undergoes preprocessing, including:
Lowercasing

Tokenization

Stopword removal

Stemming

TF-IDF vectorization

ğŸ— Model Training & Deployment

ğŸ”¹ 1. Data Preprocessing

Convert text to lowercase.

Tokenize text into individual words.

Remove non-alphanumeric characters.

Remove stopwords (common words that donâ€™t add much meaning, e.g., "the", "is").

Apply stemming (reducing words to their root form, e.g., "running" â†’ "run").

ğŸ”¹ 2. Feature Extraction (TF-IDF Vectorization)

After preprocessing, use Term Frequency-Inverse Document Frequency (TF-IDF) to convert text into a numerical representation:

Term Frequency (TF): Measures how frequently a term appears in a document.

Inverse Document Frequency (IDF): Reduces the importance of common words across multiple documents.

Using TfidfVectorizer from Scikit-learn, we transform the processed text into a feature matrix for model training.

ğŸ”¹ 3. Model Training

used Multinomial NaÃ¯ve Bayes, a probabilistic algorithm effective for text classification tasks.

ğŸ”¹ 4. Deployment

Use Streamlit for the user interface.
Deploy on Render.

ğŸ™Œ Acknowledgements

NLTK for text preprocessing

Scikit-learn for model training

Streamlit for UI development

Render for free hosting
